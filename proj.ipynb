{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Classes in Directory:\n",
      "['Acne and Rosacea Photos', 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions', 'Atopic Dermatitis Photos', 'Cellulitis Impetigo and other Bacterial Infections', 'Eczema Photos', 'Exanthems and Drug Eruptions', 'Herpes HPV and other STDs Photos', 'Light Diseases and Disorders of Pigmentation', 'Lupus and other Connective Tissue diseases', 'Melanoma Skin Cancer Nevi and Moles', 'Poison Ivy Photos and other Contact Dermatitis', 'Psoriasis pictures Lichen Planus and related diseases', 'Seborrheic Keratoses and other Benign Tumors', 'Systemic Disease', 'Tinea Ringworm Candidiasis and other Fungal Infections', 'Urticaria Hives', 'Vascular Tumors', 'Vasculitis Photos', 'Warts Molluscum and other Viral Infections']\n"
     ]
    }
   ],
   "source": [
    "train_dir = r\"C:\\Users\\PMLS\\Downloads\\datasets\\augmentation\\Dataset\\train\"  \n",
    "class_names = sorted(os.listdir(train_dir))  \n",
    "num_classes = len(class_names)\n",
    "print(\"Detected Classes in Directory:\")\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corrected Class Indices Mapping:\n",
      "{'Acne and Rosacea Photos': 0, 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions': 1, 'Atopic Dermatitis Photos': 2, 'Cellulitis Impetigo and other Bacterial Infections': 3, 'Eczema Photos': 4, 'Exanthems and Drug Eruptions': 5, 'Herpes HPV and other STDs Photos': 6, 'Light Diseases and Disorders of Pigmentation': 7, 'Lupus and other Connective Tissue diseases': 8, 'Melanoma Skin Cancer Nevi and Moles': 9, 'Poison Ivy Photos and other Contact Dermatitis': 10, 'Psoriasis pictures Lichen Planus and related diseases': 11, 'Seborrheic Keratoses and other Benign Tumors': 12, 'Systemic Disease': 13, 'Tinea Ringworm Candidiasis and other Fungal Infections': 14, 'Urticaria Hives': 15, 'Vascular Tumors': 16, 'Vasculitis Photos': 17, 'Warts Molluscum and other Viral Infections': 18}\n"
     ]
    }
   ],
   "source": [
    "class_indices = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "print(\"\\nCorrected Class Indices Mapping:\")\n",
    "print(class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2092 images belonging to 19 classes.\n",
      "Found 517 images belonging to 19 classes.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Step 3: Data Augmentation & Generators\n",
    "batch_size = 32\n",
    "image_size = (224, 224)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0,validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"sparse\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"sparse\",\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computed Class Weights:\n",
      "{0: 3.105952380952381, 1: 8.102484472049689, 2: 26.09, 3: 40.13846153846154, 4: 74.54285714285714, 5: 130.45, 6: 65.225, 7: 8.725752508361204, 8: 28.988888888888887, 9: 108.70833333333333, 10: 42.08064516129032, 11: 42.08064516129032, 12: 32.6125, 13: 32.20987654320987, 14: 21.385245901639344, 15: 869.6666666666666, 16: 25.831683168316832, 17: 173.93333333333334, 18: 10.52016129032258}\n"
     ]
    }
   ],
   "source": [
    "class_counts = {class_name: len(os.listdir(os.path.join(train_dir, class_name))) for class_name in class_names}\n",
    "total_samples = sum(class_counts.values())\n",
    "\n",
    "class_weights = {class_indices[class_name]: total_samples / count for class_name, count in class_counts.items()}\n",
    "\n",
    "print(\"\\nComputed Class Weights:\")\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.0731 - loss: 262.5596 - val_accuracy: 0.0368 - val_loss: 2.9469\n",
      "Epoch 2/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.1218 - loss: 55.6466 - val_accuracy: 0.0851 - val_loss: 2.9206\n",
      "Epoch 3/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.2241 - loss: 49.4051 - val_accuracy: 0.0909 - val_loss: 2.8981\n",
      "Epoch 4/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1s/step - accuracy: 0.3575 - loss: 35.5979 - val_accuracy: 0.1238 - val_loss: 2.9220\n",
      "Epoch 5/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - accuracy: 0.5763 - loss: 18.8059 - val_accuracy: 0.1954 - val_loss: 2.8059\n",
      "Epoch 6/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - accuracy: 0.7476 - loss: 11.6866 - val_accuracy: 0.1857 - val_loss: 3.1215\n",
      "Epoch 7/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - accuracy: 0.8393 - loss: 7.1559 - val_accuracy: 0.2089 - val_loss: 3.2336\n",
      "Epoch 8/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.8944 - loss: 5.1844 - val_accuracy: 0.2669 - val_loss: 3.2146\n",
      "Epoch 9/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.9460 - loss: 3.9475 - val_accuracy: 0.3366 - val_loss: 3.2333\n",
      "Epoch 10/10\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.9661 - loss: 3.0596 - val_accuracy: 0.3056 - val_loss: 3.2623\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 266ms/step - accuracy: 0.9831 - loss: 0.2418\n",
      "\n",
      "✅ Test Accuracy: 98.04%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(train_generator)\n",
    "print(f\"\\n✅ Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ✅ Save Model\n",
    "model.save(\"cnn_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
